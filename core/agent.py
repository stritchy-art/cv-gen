"""
Agent principal pour la conversion de CV PDF en DOCX via LLM
Ce script orchestre le processus complet :
1. Extraction du contenu PDF
2. Traitement par LLM (OpenAI)
3. G√©n√©ration du fichier DOCX format√©
"""

import os
import json
import hashlib
from pathlib import Path
from typing import Tuple, Optional
from openai import OpenAI
from dotenv import load_dotenv
from diskcache import Cache

from core.pdf_extractor import extract_pdf_content
from core.docx_extractor import extract_docx_content
from core.docx_generator import generate_docx_from_cv_data
import docx2txt

# Charger le fichier .env
load_dotenv()

# Cache global avec TTL de 15 jours (en secondes)
CACHE_DIR = Path(__file__).parent.parent / "cache" / "llm_responses"
CACHE_DIR.mkdir(parents=True, exist_ok=True)
llm_cache = Cache(str(CACHE_DIR))
CACHE_TTL = 15 * 24 * 60 * 60  # 15 jours en secondes

class CVConverterAgent:
    def __init__(self):
        """
        Initialise l'agent avec OpenAI
        
        Variables d'environnement requises:
            OPENAI_API_KEY: Cl√© API OpenAI
            OPENAI_MODEL: Nom du mod√®le (optionnel, d√©faut: gpt-5-mini)
        """
        # V√©rification de la cl√© API OpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("Variable d'environnement OPENAI_API_KEY requise")
        
        self.client = OpenAI(api_key=api_key)
        
        # Mod√®le par d√©faut ou personnalis√©
        self.model = os.getenv("OPENAI_MODEL", "gpt-5-mini")
    
    def _generate_cache_key(self, pdf_content: str, improve_content: bool, improvement_mode: str, job_offer_content: Optional[str] = None) -> str:
        """G√©n√®re une cl√© de cache unique bas√©e sur le contenu et les options
        
        Args:
            pdf_content: Contenu du PDF
            improve_content: Am√©lioration activ√©e ou non
            improvement_mode: Mode d'am√©lioration
            job_offer_content: Contenu de l'appel d'offres (optionnel)
            
        Returns:
            str: Cl√© de cache unique
        """
        # Cr√©er un hash du contenu du PDF
        content_hash = hashlib.sha256(pdf_content.encode()).hexdigest()[:16]
        
        # Ajouter le hash de l'appel d'offres si pr√©sent
        job_hash = ""
        if job_offer_content:
            job_hash = "_" + hashlib.sha256(job_offer_content.encode()).hexdigest()[:8]
        
        # Cl√© composite
        cache_key = f"cv_{content_hash}_{improvement_mode}_{improve_content}{job_hash}"
        return cache_key
    
    def extract_job_offer_content(self, job_offer_path: str) -> str:
        """Extrait le contenu d'un appel d'offres (PDF, DOCX ou TXT)
        
        Args:
            job_offer_path: Chemin vers le fichier de l'appel d'offres
            
        Returns:
            str: Contenu textuel de l'appel d'offres
        """
        file_path = Path(job_offer_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"Fichier d'appel d'offres introuvable: {job_offer_path}")
        
        extension = file_path.suffix.lower()
        
        try:
            if extension == '.pdf':
                content = extract_pdf_content(job_offer_path)
            elif extension in ['.docx', '.doc']:
                content = docx2txt.process(job_offer_path)
            elif extension == '.txt':
                with open(job_offer_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:
                raise ValueError(f"Format de fichier non support√©: {extension}")
            
            print(f"‚úì Appel d'offres extrait ({len(content)} caract√®res)")
            return content
            
        except Exception as e:
            print(f"‚úó Erreur lors de l'extraction de l'appel d'offres : {e}")
            raise
    
    def extract_structured_data_with_llm(self, pdf_text: str, improve_content: bool = False, improvement_mode: str = "none", job_offer_content: Optional[str] = None, max_pages: Optional[int] = None, target_language: Optional[str] = None, model: str = "gpt-4o-mini") -> dict:
        """Utilise le LLM pour extraire les donn√©es structur√©es du CV
        
        Args:
            pdf_text: Texte extrait du PDF
            improve_content: Si True, le LLM peut am√©liorer le contenu
            improvement_mode: Mode d'am√©lioration (none, basic, targeted)
            job_offer_content: Contenu de l'appel d'offres pour l'am√©lioration cibl√©e
            max_pages: Nombre maximum de pages (optionnel)
            target_language: Langue cible pour la traduction (optionnel: en, it, es)
            model: Mod√®le OpenAI √† utiliser
            
        Returns:
            dict: Donn√©es structur√©es du CV
        """
        # V√©rifier le cache
        cache_key = self._generate_cache_key(pdf_text, improve_content, improvement_mode, job_offer_content)
        
        if cache_key in llm_cache:
            print("‚úì Donn√©es trouv√©es dans le cache (pas d'appel LLM)")
            return llm_cache[cache_key]
        
        print("‚è≥ Donn√©es non trouv√©es dans le cache, appel du LLM...")
        
        # Mappage des langues
        language_names = {
            'en': 'ANGLAIS',
            'it': 'ITALIEN',
            'es': 'ESPAGNOL'
        }
        
        # Instruction de traduction si langue cible sp√©cifi√©e
        translation_instruction = ""
        if target_language and target_language != 'fr':
            lang_name = language_names.get(target_language, target_language.upper())
            translation_instruction = f"""
            
üåê TRADUCTION OBLIGATOIRE : TOUT le contenu du CV doit √™tre traduit en {lang_name}.
- Traduis TOUS les textes : titres de poste, descriptions d'activit√©s, comp√©tences, formations
- Garde les noms propres (entreprises, personnes, villes) dans leur langue d'origine
- Adapte les termes techniques au vocabulaire professionnel {lang_name.lower()}
- Les dates restent au format d'origine
"""
        
        # Prompt de base selon le mode d'am√©lioration
        if improvement_mode == "targeted" and job_offer_content:
            prompt = f"""Tu es un expert en r√©daction de CV professionnels et en matching candidat-mission. 
            Analyse le texte du CV suivant ET l'appel d'offres fourni, puis ADAPTE et AM√âLIORE le contenu du CV pour le rendre plus pertinent vis-√†-vis de cette mission.
            {translation_instruction}
            
            R√àGLES IMPORTANTES POUR L'AM√âLIORATION CIBL√âE:
            - NE MENS JAMAIS : conserve les informations factuelles (dates, entreprises, dipl√¥mes)
            - Reformule et r√©organise les descriptions d'activit√©s pour mettre en avant les comp√©tences pertinentes pour la mission
            - Enrichis le vocabulaire technique en lien avec l'appel d'offres
            - Mets en avant les exp√©riences et comp√©tences qui correspondent aux besoins de la mission
            - Reste factuel et professionnel, n'invente pas d'exp√©riences ou de comp√©tences
            - Si certaines comp√©tences demand√©es sont pr√©sentes mais peu visibles, reformule pour les mettre en valeur
            
            Retourne un JSON structur√© avec EXACTEMENT ce format :"""
        elif improve_content or improvement_mode == "basic":
            prompt = f"""Tu es un expert en r√©daction de CV professionnels. 
            Analyse le texte du CV suivant, AM√âLIORE le contenu (reformule, corrige les fautes, enrichis les descriptions, rends plus professionnel) et retourne un JSON structur√© avec EXACTEMENT ce format :
            {translation_instruction}"""
        else:
            prompt = f"""Tu es un expert en extraction de donn√©es de CV. 
            Analyse le texte du CV suivant et retourne un JSON structur√© avec EXACTEMENT ce format :
            {translation_instruction}"""
        
        # Ajouter une instruction sp√©ciale si limitation de pages activ√©e
        if max_pages:
            max_activities_per_exp = 3 if max_pages <= 2 else 4
            max_skills_categories = 4 if max_pages <= 2 else 6
            max_skills_assessment = 8 if max_pages <= 2 else 10
            
            prompt += f"""

            üö® CONTRAINTE ABSOLUE : Le CV final NE DOIT PAS d√©passer {max_pages} page(s) au format DOCX.
            
            STRAT√âGIE DE R√âDUCTION INTELLIGENTE :
            
            1. EXP√âRIENCES PROFESSIONNELLES : 
               - GARDE TOUTES les exp√©riences (ne supprime AUCUNE exp√©rience)
               - MAIS condense chacune au maximum :
                 * {max_activities_per_exp} activit√©s/r√©alisations MAXIMUM par exp√©rience
                 * Chaque activit√© : UNE ligne (80-100 caract√®res max), ultra-concise
                 * Contexte : 1 phrase courte (30-50 caract√®res)
                 * Environnement technique : 1 ligne courte avec 5-8 technologies cl√©s UNIQUEMENT
            
            2. COMP√âTENCES TECHNIQUES (PRIORISATION INTELLIGENTE) :
               - {max_skills_categories} cat√©gories MAXIMUM
               - Dans chaque cat√©gorie : liste UNIQUEMENT les technologies qui apparaissent dans "skills_assessment" avec un niveau √©lev√© (>70)
               - 5-8 technologies par cat√©gorie (les mieux ma√Ætris√©es)
               - Supprime les technologies mineures ou peu utilis√©es
            
            3. SKILLS ASSESSMENT (S√âLECTION DES MEILLEURES) :
               - {max_skills_assessment} comp√©tences MAXIMUM
               - PRIORISE les comp√©tences avec le niveau le plus √©lev√©
               - Garde les technologies strat√©giques et demand√©es sur le march√©
               - √âlimine les comp√©tences basiques ou d√©pass√©es
            
            4. FORMATIONS :
               - 2-3 formations MAXIMUM (les plus r√©centes ou les plus prestigieuses)
               - Format ultra-compact sur 1 ligne
            
            5. COMP√âTENCES OP√âRATIONNELLES :
               - 5-6 items MAXIMUM
               - Formulation tr√®s concise (2-4 mots par comp√©tence)
            
            ‚ö° OBJECTIF : CV dense mais complet, avec TOUTES les exp√©riences mais en version ultra-condens√©e.
            
            """
        
        
        prompt += """

            {
                "header": {
                    "name": "Nom complet",
                    "title": "Titre du poste",
                    "experience": "X ans d'exp√©rience (OBLIGATOIRE - extrais ou calcule depuis les exp√©riences)"
                },
                "suggested_tjm": 500,
                "skills_assessment": [
                    {"skill": "Nom de la technologie/m√©thodologie", "level": 85}
                ],
                "competences": {
                    "operationnelles": ["liste des comp√©tences op√©rationnelles"],
                    "techniques": [
                        {"category": "Nom de la cat√©gorie", "items": ["tech1", "tech2", "tech3"]}
                    ]
                },
                "formations": [
                    {"year": "ann√©e", "description": "description de la formation"}
                ],
                "experiences": [
                    {
                        "company": "Entreprise / Soci√©t√© (Ville)",
                        "period": "P√©riode",
                        "title": "Titre du poste",
                        "context": "Texte du contexte",
                        "activities": ["liste des activit√©s"],
                        "tech_env": "Environnement technique"
                    }
                ]
            }

            R√àGLES IMPORTANTES : 
            - "experience" dans header est OBLIGATOIRE : si le CV mentionne "X ans d'exp√©rience", utilise cette valeur. Sinon, calcule approximativement depuis les dates des exp√©riences professionnelles
            - "suggested_tjm" : Sugg√®re un Taux Journalier Moyen (TJM) en euros bas√© sur :
              * Le niveau d'exp√©rience (junior: 350-450‚Ç¨, confirm√©: 450-550‚Ç¨, senior: 550-650‚Ç¨, expert: 650-850‚Ç¨)
              * La complexit√© et la raret√© des comp√©tences techniques
              * Le niveau de responsabilit√© et d'autonomie d√©montr√©
              * Les certifications et formations sp√©cialis√©es
              * Le march√© fran√ßais du conseil IT/Tech
              * Sois r√©aliste et align√© sur les tarifs du march√©
            - "skills_assessment" : √©value le niveau de ma√Ætrise (0-100) de chaque technologie/m√©thodologie en te basant sur :
              * La fr√©quence d'utilisation dans les exp√©riences
              * Le contexte d'utilisation (projet complexe = niveau plus √©lev√©)
              * Les certifications ou formations mentionn√©es
              * La dur√©e d'utilisation (plus ancien = niveau potentiellement plus √©lev√©)
              * Liste les 8-12 comp√©tences techniques principales
            - "period" doit TOUJOURS √™tre au format "{Mois} {Ann√©e} √† {Mois} {Ann√©e}" avec le mois en toutes lettres avec majuscule (ex: "Octobre 2021 √† aujourd'hui", "Septembre 2019 √† Octobre 2021", "Janvier 2014 √† Septembre 2014")
            - Si une exp√©rience est en cours, utilise "√† aujourd'hui" comme date de fin
            - "company" doit contenir UNIQUEMENT le nom de l'entreprise/soci√©t√© et la ville entre parenth√®ses, par exemple "MAIF / CONSERTO (NIORT)"
            - "title" doit contenir UNIQUEMENT le titre du poste, par exemple "ING√âNIEUR SYST√àMES - OPS"
            - Ne m√©lange JAMAIS le nom de l'entreprise avec le titre du poste
            - Pour les comp√©tences techniques, groupe-les par cat√©gorie (ex: "Virtualisation", "Base de donn√©es", "Stack DevOps", etc.) avec "category" et "items" comme array
            - Extrais TOUTES les informations pr√©sentes dans le CV
            """
        
        # Ajout des r√®gles selon le mode
        if improvement_mode == "targeted" and job_offer_content:
            prompt += f"""
            
            APPEL D'OFFRES / MISSION :
            {job_offer_content[:3000]}  # Limiter √† 3000 caract√®res pour ne pas d√©passer les limites
            
            INSTRUCTIONS D'AM√âLIORATION CIBL√âE:
            - Analyse les comp√©tences et exp√©riences requises dans l'appel d'offres
            - Adapte les descriptions d'activit√©s pour mettre en avant ce qui correspond √† la mission
            - Enrichis le vocabulaire technique en coh√©rence avec l'appel d'offres
            - Restructure les informations pour maximiser la pertinence vis-√†-vis de la mission
            - RESTE FACTUEL : ne mens jamais, n'invente pas de comp√©tences ou d'exp√©riences
            """
        elif improve_content or improvement_mode == "basic":
            prompt += """
            - AM√âLIORE le contenu : reformule les phrases pour les rendre plus professionnelles, corrige les fautes, enrichis les descriptions
            - Am√©liore la clart√© et l'impact des descriptions d'activit√©s
            - Rends le vocabulaire plus technique et professionnel
            - Corrige toutes les fautes d'orthographe et de grammaire
            """
        else:
            prompt += """
            - Pr√©serve le formatage, les majuscules et la ponctuation originaux
            - NE MODIFIE PAS le contenu, extrais-le fid√®lement tel quel
            - Ne corrige PAS les fautes, ne reformule PAS les phrases
            """
        
        prompt += """
            - Retourne UNIQUEMENT le JSON, sans texte avant ou apr√®s

            Texte du CV :
            """
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "Tu es un assistant sp√©cialis√© dans l'extraction de donn√©es structur√©es √† partir de CV. Tu retournes uniquement du JSON valide."},
                    {"role": "user", "content": prompt + pdf_text}
                ],
                #temperature=0.1,  # Faible temp√©rature pour plus de pr√©cision
                response_format={"type": "json_object"}  # Force le format JSON
            )
            
            json_response = response.choices[0].message.content
            cv_data = json.loads(json_response)
            
            # Stocker dans le cache avec TTL de 15 jours
            llm_cache.set(cache_key, cv_data, expire=CACHE_TTL)
            
            print("‚úì Extraction structur√©e r√©ussie via LLM (mis en cache)")
            return cv_data
            
        except Exception as e:
            print(f"‚úó Erreur lors de l'extraction structur√©e : {e}")
            raise
    
    def generate_profile_pitch(self, cv_data, job_offer_content=None, model="gpt-4o-mini"):
        """G√©n√®re un pitch de profil pour pr√©senter le candidat √† un client
        
        Args:
            cv_data: Donn√©es structur√©es du CV
            job_offer_content: Contenu de l'appel d'offres (optionnel, pour pitch cibl√©)
            model: Mod√®le OpenAI √† utiliser
            
        Returns:
            str: Pitch de pr√©sentation du profil
        """
        # G√©n√©rer une cl√© de cache pour le pitch
        cache_data = json.dumps(cv_data, sort_keys=True)
        cache_key_input = cache_data + (job_offer_content or "")
        pitch_cache_key = "pitch_" + hashlib.sha256(cache_key_input.encode()).hexdigest()[:24]
        
        # V√©rifier le cache
        cached_pitch = llm_cache.get(pitch_cache_key)
        if cached_pitch:
            print("‚úì Pitch r√©cup√©r√© depuis le cache")
            return cached_pitch
        
        header = cv_data.get('header', {})
        competences = cv_data.get('competences', {})
        experiences = cv_data.get('experiences', [])
        
        # Pr√©parer le contexte pour le LLM
        context = f"""
Profil : {header.get('name', '')}
Titre : {header.get('title', '')}
Exp√©rience : {header.get('experience', '')}

Comp√©tences op√©rationnelles : {', '.join(competences.get('operationnelles', []))}

Exp√©riences r√©centes :
"""
        for exp in experiences[:3]:  # 3 premi√®res exp√©riences
            context += f"- {exp.get('company', '')} : {exp.get('title', '')}\n"
        
        # Adapter le prompt en fonction de la pr√©sence d'un appel d'offres
        if job_offer_content:
            prompt = f"""Tu es un consultant RH expert. R√©dige un pitch professionnel et concis (150-200 mots maximum) pour pr√©senter ce candidat √† un client DANS LE CONTEXTE DE L'APPEL D'OFFRES CI-DESSOUS.

Le pitch doit :
- √ätre r√©dig√© √† la 3√®me personne
- Mettre en avant les comp√©tences et exp√©riences EN LIEN DIRECT avec les exigences de l'appel d'offres
- Montrer comment le candidat r√©pond sp√©cifiquement aux besoins du client
- √ätre percutant et professionnel
- Mentionner UNIQUEMENT les √©l√©ments pertinents pour cette mission
- √ätre adapt√© pour une pr√©sentation √©crite √† un client

Donn√©es du profil :
{context}

Appel d'offres / Mission :
{job_offer_content[:2000]}

R√©dige le pitch directement, sans introduction ni conclusion. Concentre-toi sur l'ad√©quation entre le profil et la mission."""
        else:
            prompt = f"""Tu es un consultant RH expert. R√©dige un pitch professionnel et concis (150-200 mots maximum) pour pr√©senter ce candidat √† un client.

Le pitch doit :
- √ätre r√©dig√© √† la 3√®me personne
- Mettre en valeur les points forts et l'expertise
- √ätre percutant et professionnel
- Mentionner l'exp√©rience, les comp√©tences cl√©s et la valeur ajout√©e
- √ätre adapt√© pour une pr√©sentation √©crite √† un client

Donn√©es du profil :
{context}

R√©dige le pitch directement, sans introduction ni conclusion."""
        
        try:
            print("üîÑ G√©n√©ration du pitch via OpenAI API...")
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "Tu es un consultant RH expert en r√©daction de pr√©sentations professionnelles."},
                    {"role": "user", "content": prompt}
                ],
                #temperature=0.7,  # Un peu de cr√©ativit√© pour le pitch
                max_completion_tokens=1000
            )
            
            pitch = response.choices[0].message.content.strip() if response.choices[0].message.content else ""
            
            if not pitch:
                print(f"[WARNING] Le pitch est vide! finish_reason: {response.choices[0].finish_reason}")
                print(f"[WARNING] Mod√®le utilis√©: {self.model}")
                print(f"[WARNING] Longueur du contexte: {len(context)} caract√®res")
                return None
            
            # Mettre en cache le pitch g√©n√©r√©
            llm_cache.set(pitch_cache_key, pitch, expire=CACHE_TTL)
            print("‚úì Pitch g√©n√©r√© et mis en cache")
            
            return pitch
            
        except Exception as e:
            print(f"[ERROR] Erreur lors de la g√©n√©ration du pitch:")
            print(f"[ERROR] Type: {type(e).__name__}")
            print(f"[ERROR] Message: {str(e)}")
            import traceback
            print(f"[ERROR] Traceback:\n{traceback.format_exc()}")
            print(f"[ERROR] Mod√®le utilis√©: {self.model}")
            print(f"[ERROR] Cl√© API pr√©sente: {bool(os.getenv('OPENAI_API_KEY'))}")
            return None
    
    def process_cv(self, pdf_path, output_path=None, generate_pitch=True, improve_content=False, improvement_mode="none", job_offer_path=None, candidate_name=None, max_pages=None, target_language=None, model="gpt-4o-mini"):
        """Traite un CV (PDF ou DOCX) et g√©n√®re un fichier DOCX format√©
        
        Args:
            pdf_path: Chemin vers le fichier CV d'entr√©e (PDF ou DOCX)
            output_path: Chemin vers le fichier DOCX de sortie (optionnel)
            generate_pitch: G√©n√©rer ou non le pitch de pr√©sentation (optionnel, True par d√©faut)
            improve_content: Am√©liorer le contenu avec le LLM (optionnel, False par d√©faut)
            improvement_mode: Mode d'am√©lioration (none, basic, targeted)
            job_offer_path: Chemin vers le fichier d'appel d'offres (requis si improvement_mode=targeted)
            candidate_name: Nom du candidat (optionnel, remplacera le nom extrait)
            max_pages: Nombre maximum de pages (optionnel)
            target_language: Langue cible pour la traduction (optionnel: fr, en, it, es)
            model: Mod√®le OpenAI √† utiliser (gpt-4o, gpt-4o-mini, gpt-3.5-turbo)
            
        Returns:
            Tuple[str, dict]: Chemin du fichier DOCX g√©n√©r√© et donn√©es structur√©es du CV
        """
        print(f"\n{'='*60}")
        print(f"Traitement du CV : {Path(pdf_path).name}")
        print(f"{'='*60}\n")
        
        # D√©tecter le type de fichier
        input_file = Path(pdf_path)
        file_extension = input_file.suffix.lower()
        
        # √âtape 1 : Extraction du contenu
        print(f"√âtape 1/3 : Extraction du contenu {file_extension.upper()}...")
        
        if file_extension == '.pdf':
            cv_text = extract_pdf_content(pdf_path)
        elif file_extension in ['.docx', '.doc']:
            cv_text = extract_docx_content(pdf_path)
        else:
            raise ValueError(f"Format de fichier non support√©: {file_extension}. Formats accept√©s: PDF, DOCX, DOC")
        
        if not cv_text or len(cv_text.strip()) < 100:
            raise ValueError("Le contenu extrait du CV est insuffisant ou vide")
        
        print(f"‚úì {len(cv_text)} caract√®res extraits\n")
        
        # √âtape optionnelle : Extraction de l'appel d'offres
        job_offer_content = None
        if improvement_mode == "targeted" and job_offer_path:
            print("Extraction de l'appel d'offres...")
            job_offer_content = self.extract_job_offer_content(job_offer_path)
            print()
        
        # √âtape 2 : Traitement par LLM
        print("√âtape 2/4 : Analyse et structuration via LLM...")
        if target_language and target_language != 'fr':
            language_names = {'en': 'Anglais', 'it': 'Italien', 'es': 'Espagnol'}
            print(f"üåê TRADUCTION ACTIV√âE : Le CV sera traduit en {language_names.get(target_language, target_language.upper())}")
        if max_pages:
            print(f"üö® MODE R√âDUCTION ACTIV√â : CV limit√© √† {max_pages} page(s) maximum !")
        if improvement_mode == "targeted":
            print("üéØ Mode am√©lioration cibl√©e activ√© - Le CV sera adapt√© √† l'appel d'offres")
        elif improve_content or improvement_mode == "basic":
            print("‚ö†Ô∏è  Mode am√©lioration basique activ√© - Le LLM va am√©liorer le contenu")
        cv_data = self.extract_structured_data_with_llm(cv_text, improve_content=improve_content, improvement_mode=improvement_mode, job_offer_content=job_offer_content, max_pages=max_pages, target_language=target_language, model=model)
        print()
        
        # Remplacer le nom si candidate_name est fourni
        if candidate_name:
            print(f"üìù Remplacement du nom par: {candidate_name}")
            if 'header' not in cv_data:
                cv_data['header'] = {}
            cv_data['header']['name'] = candidate_name
        
        # √âtape 3 : G√©n√©ration du DOCX
        print("√âtape 3/4 : G√©n√©ration du fichier Word...")
        
        if output_path is None:
            # Utiliser le nom du candidat (fourni ou extrait) pour le fichier
            person_name = cv_data.get('header', {}).get('name', '')
            if person_name:
                # Nettoyer le nom pour un nom de fichier valide
                safe_name = "".join(c for c in person_name if c.isalnum() or c in (' ', '-', '_')).strip()
                safe_name = safe_name.replace(' ', '_')
                output_path = Path(pdf_path).parent / f"{safe_name}_CV.docx"
            else:
                # Fallback : utiliser le nom du fichier PDF original
                input_name = Path(pdf_path).stem
                output_path = Path(pdf_path).parent / f"{input_name}_converti.docx"
        
        # G√©n√©rer le DOCX avec la langue cible
        output_file = generate_docx_from_cv_data(cv_data, output_path, target_language=target_language)
        print()
        
        # √âtape 4 : G√©n√©ration du pitch de profil (optionnel)
        pitch = None
        if generate_pitch:
            print("√âtape 4/4 : G√©n√©ration du pitch de pr√©sentation...")
            # Passer le contenu de l'appel d'offres si disponible pour un pitch cibl√©
            pitch = self.generate_profile_pitch(cv_data, job_offer_content=job_offer_content, model=model)
            if pitch:
                print(f"‚úì Pitch g√©n√©r√© ({len(pitch)} caract√®res)")
                if job_offer_content:
                    print("üéØ Pitch cibl√© pour l'appel d'offres")
                print(f"\nPitch de profil :\n{'-'*60}\n{pitch}\n{'-'*60}\n")
            else:
                print("‚úó √âchec de la g√©n√©ration du pitch\n")
        else:
            print("√âtape 4/4 : G√©n√©ration du pitch ignor√©e (option d√©sactiv√©e)\n")
        
        # Ajouter le pitch aux donn√©es CV pour le retour
        if pitch:
            cv_data['pitch'] = pitch
        
        print(f"\n{'='*60}")
        print(f"‚úì Conversion termin√©e avec succ√®s !")
        print(f"Fichier g√©n√©r√© : {output_file}")
        print(f"{'='*60}\n")
        
        return str(output_file), cv_data


def main():
    """Fonction principale pour l'ex√©cution en ligne de commande"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Convertit un CV PDF en fichier Word format√© via LLM"
    )
    parser.add_argument(
        "pdf_path",
        help="Chemin vers le fichier PDF √† convertir"
    )
    parser.add_argument(
        "-o", "--output",
        help="Chemin du fichier DOCX de sortie (optionnel)",
        default=None
    )
    
    args = parser.parse_args()
    
    # V√©rification du fichier d'entr√©e
    if not Path(args.pdf_path).exists():
        print(f"‚úó Erreur : Le fichier '{args.pdf_path}' n'existe pas")
        return 1
    
    try:
        # Cr√©ation de l'agent et traitement
        agent = CVConverterAgent()
        agent.process_cv(args.pdf_path, args.output)
        return 0
        
    except Exception as e:
        print(f"\n‚úó Erreur durant le traitement : {e}")
        return 1


if __name__ == "__main__":
    exit(main())
